<!DOCTYPE html>
<html lang="chinese (simplified)">

<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="generator" content="Pelican" />
    <meta name="description" content="迈达斯之手 Blog Posts">
    <title>CUDA基础知识（一）</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css" />
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto+Slab|Ruda" />
    <link rel="stylesheet" type="text/css" href="/theme/css/main.css" />
    <link rel="stylesheet" type="text/css" href="/theme/css/pygment.css" />
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" href="/theme/css/stork.css">
    <link rel="stylesheet" media="screen and (prefers-color-scheme: dark)"
        href="/theme/css/stork-dark.css">
    <link
        href="/feeds/all.atom.xml"
        type="application/atom+xml" rel="alternate" title="迈达斯之手 Atom Feed" />
<meta name="description" content="CUDA的软硬基础概念辨析： 在CUDA编程中，SM（Streaming Multiprocessor）和SP（Streaming Processor）是硬件概念，而grid、block和thread是软件概念。以下是这些概念的简要描述以及它们之间的相互关系： SM（Streaming..." />
</head>

<body class="min-h-screen flex flex-col max-w-7xl lg:max-w-none text-zinc-800 bg-neutral-100 
    dark:bg-neutral-900 dark:text-zinc-300 container mx-auto justify-center md:px-3 ">
    <script>
        if (localStorage.getItem('color-theme') === 'dark' || (!('color-theme' in localStorage) && window.matchMedia(
                '(prefers-color-scheme: dark)').matches)) {
            document.documentElement.classList.add('dark');
        } else {
            document.documentElement.classList.remove('dark')
        }
    </script>
    <nav class="sm:flex sm:justify-between xl:ml-32 pl-4 items-center">
        <div class="flex pt-4">
            <h1 class="font-semibold text-2xl"><a href="/">迈达斯之手</a></h1>
            <button id="theme-toggle" type="button" aria-label="Light|Dark"
                class="text-zinc-700 dark:text-zinc-400 rounded-full focus:outline-none text-sm ml-2 p-1">
                <svg id="theme-toggle-dark-icon" class="w-5 h-5 hidden" fill="currentColor" viewBox="0 0 20 20"
                    xmlns="http://www.w3.org/2000/svg">
                    <path d="M17.293 13.293A8 8 0 016.707 2.707a8.001 8.001 0 1010.586 10.586z"></path>
                </svg>
                <svg id="theme-toggle-light-icon" class="w-5 h-5 hidden" fill="currentColor" viewBox="0 0 20 20"
                    xmlns="http://www.w3.org/2000/svg">
                    <path
                        d="M10 2a1 1 0 011 1v1a1 1 0 11-2 0V3a1 1 0 011-1zm4 8a4 4 0 11-8 0 4 4 0 018 0zm-.464 4.95l.707.707a1 1 0 001.414-1.414l-.707-.707a1 1 0 00-1.414 1.414zm2.12-10.607a1 1 0 010 1.414l-.706.707a1 1 0 11-1.414-1.414l.707-.707a1 1 0 011.414 0zM17 11a1 1 0 100-2h-1a1 1 0 100 2h1zm-7 4a1 1 0 011 1v1a1 1 0 11-2 0v-1a1 1 0 011-1zM5.05 6.464A1 1 0 106.465 5.05l-.708-.707a1 1 0 00-1.414 1.414l.707.707zm1.414 8.486l-.707.707a1 1 0 01-1.414-1.414l.707-.707a1 1 0 011.414 1.414zM4 11a1 1 0 100-2H3a1 1 0 000 2h1z"
                        fill-rule="evenodd" clip-rule="evenodd"></path>
                </svg>
            </button>
        </div>
        <ul class="flex flex-wrap lg:mr-24 md:pt-0">
            <li class="mr-4 pt-6"><a  href="/archives.html">Archive</a></li>
            <li class="mr-4 pt-6"><a                     href="/categories.html">Categories</a></li>
            <li class="mr-4 pt-6"><a  href="/tags.html">Tags</a></li>
            <li class="mr-4 pt-6"><a  href="/search.html">Search</a></li>
        </ul>
    </nav>
    <div class="flex-grow md:max-w-screen-md md:mx-auto md:w-3/4 px-4">
        <nav class="text-zinc-800 dark:text-zinc-300 mt-12 pb-2 md:mt-16" aria-label="Breadcrumb">
            <ul class="p-0 inline-flex items-center">
                <li class="flex items-center">
                    <a href="/" class="text-zinc-800 dark:text-zinc-300 inline-flex items-center">
                        <svg class="w-5 h-5 mr-2" fill="currentColor" viewBox="0 0 20 20"
                            xmlns="http://www.w3.org/2000/svg">
                            <path
                                d="M10.707 2.293a1 1 0 00-1.414 0l-7 7a1 1 0 001.414 1.414L4 10.414V17a1 1 0 001 1h2a1 1 0 001-1v-2a1 1 0 011-1h2a1 1 0 011 1v2a1 1 0 001 1h2a1 1 0 001-1v-6.586l.293.293a1 1 0 001.414-1.414l-7-7z">
                            </path>
                        </svg>
                        Home
                    </a>
                    <svg class="fill-current w-3 h-3 mr-2 ml-1" xmlns="http://www.w3.org/2000/svg"
                        viewBox="0 0 320 512">
                        <path
                            d="M285.476 272.971L91.132 467.314c-9.373 9.373-24.569 9.373-33.941 0l-22.667-22.667c-9.357-9.357-9.375-24.522-.04-33.901L188.505 256 34.484 101.255c-9.335-9.379-9.317-24.544.04-33.901l22.667-22.667c9.373-9.373 24.569-9.373 33.941 0L285.475 239.03c9.373 9.372 9.373 24.568.001 33.941z" />
                    </svg>
                </li>
                <li class="flex items-center">
                    <a href="/categories.html">Categories</a>
                    <svg class="fill-current w-3 h-3 mr-2 ml-1" xmlns="http://www.w3.org/2000/svg"
                        viewBox="0 0 320 512">
                        <path
                            d="M285.476 272.971L91.132 467.314c-9.373 9.373-24.569 9.373-33.941 0l-22.667-22.667c-9.357-9.357-9.375-24.522-.04-33.901L188.505 256 34.484 101.255c-9.335-9.379-9.317-24.544.04-33.901l22.667-22.667c9.373-9.373 24.569-9.373 33.941 0L285.475 239.03c9.373 9.372 9.373 24.568.001 33.941z" />
                    </svg>
                </li>
                <li class="flex items-center">
                    <a href="/category/gao-xing-neng-ji-suan.html">高性能计算</a>
                    <svg class="fill-current w-3 h-3 mr-2 ml-1" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512">
                        <path
                            d="M285.476 272.971L91.132 467.314c-9.373 9.373-24.569 9.373-33.941 0l-22.667-22.667c-9.357-9.357-9.375-24.522-.04-33.901L188.505 256 34.484 101.255c-9.335-9.379-9.317-24.544.04-33.901l22.667-22.667c9.373-9.373 24.569-9.373 33.941 0L285.475 239.03c9.373 9.372 9.373 24.568.001 33.941z" />
                    </svg>
                </li>
            </ul>
        </nav>

<main>
  <header>
    <h1 class="font-semibold text-3xl my-2">CUDA基础知识（一）</h1>
    <footer class="flex text-sm text-zinc-800 dark:text-zinc-400">
      <div class="flex text-xs text-zinc-800 dark:text-zinc-400">
        <time>三月 22, 2023</time>
        <div>
          <span>&nbsp;·&nbsp;5 min read</span>
        </div>
        <div>
          <span>&nbsp;·&nbsp;Xiaoyu</span>
        </div>
      </div>
    </footer>
  </header>
  <details class="flex flex-col my-6 p-4 bg-zinc-200 dark:bg-zinc-800 rounded-lg">
    <summary class="text-lg font-bold">Table of contents</summary>
    <div class="mx-4 px-4 underline">
      <div id="toc"><ul><li><a class="toc-href" href="#cudade-ruan-ying-ji-chu-gai-nian-bian-xi" title="CUDA的软硬基础概念辨析：">CUDA的软硬基础概念辨析：</a></li><li><a class="toc-href" href="#shi-li-dai-ma" title="示例代码">示例代码</a></li><li><a class="toc-href" href="#dai-ma-jie-du" title="代码解读">代码解读</a><ul><li><a class="toc-href" href="#cudanei-he-de-ding-yi-yu-diao-yong" title="cuda内核的定义与调用">cuda内核的定义与调用</a></li><li><a class="toc-href" href="#xian-cheng-idshi-ru-he-fen-pei-de" title="线程id是如何分配的">线程id是如何分配的</a></li></ul></li></ul></div>
    </div>
  </details>
  <div class="max-w-7xl container mx-auto my-8 text-zinc-800 dark:text-zinc-300  
              prose lg:max-w-none prose-headings:text-zinc-800 prose-headings:dark:text-zinc-300 
              prose-h1:text-3xl lg:prose-h1:text-3xl prose-headings:font-semibold 
              prose-pre:bg-zinc-200 prose-pre:text-zinc-800
              dark:prose-pre:bg-zinc-800 dark:prose-pre:text-zinc-200
              prose-blockquote:text-zinc-800
              dark:prose-blockquote:text-zinc-200
              prose-a:text-slate-600 prose-a:font-normal
              dark:prose-a:text-slate-400
              dark:prose-strong:text-zinc-200 
              dark:prose-code:text-zinc-200
              dark:prose-code:bg-zinc-800
              prose-code:bg-zinc-200
              prose-code:font-light
              prose-img:rounded-md
              sm:text-left md:text-justify
              ">
    <h2 id="cudade-ruan-ying-ji-chu-gai-nian-bian-xi">CUDA的软硬基础概念辨析：</h2>
<p>在CUDA编程中，SM（Streaming Multiprocessor）和SP（Streaming Processor）是硬件概念，而grid、block和thread是软件概念。以下是这些概念的简要描述以及它们之间的相互关系：</p>
<ol>
<li>
<p>SM（Streaming Multiprocessor）：SM是NVIDIA GPU中的一个核心组件，负责执行并行任务。一个GPU通常包含多个SM，每个SM可以同时处理多个block。</p>
</li>
<li>
<p>SP（Streaming Processor）：SP是SM内的一个处理单元，用于执行具体的计算任务。一个SM包含多个SP。CUDA编程模型将这些处理单元称为CUDA核心。</p>
</li>
<li>
<p>grid：grid是软件概念，表示一组线程块（block）的集合。grid的维度由程序员在主机代码中指定。grid中的block会被映射到GPU的SM上进行执行。</p>
</li>
<li>
<p>block：block也是软件概念，表示一组线程的集合。每个block内的线程可以共享内存并进行同步操作。block的维度同样由程序员指定。block中的线程会被映射到SM内的SP上进行执行。</p>
</li>
<li>
<p>thread：thread是CUDA编程模型中的基本执行单元，代表一个独立的执行流。每个线程负责执行kernel函数的一个实例。线程在block内进行组织，而block又在grid内进行组织。</p>
</li>
</ol>
<p>相互映射关系如下：</p>
<ul>
<li>grid映射到GPU上的一个或多个SM上。一个SM可以同时处理多个block，但一个block始终在同一个SM上运行。</li>
<li>block映射到SM内的一组SP上。一个block内的所有线程会在同一个SM上运行。</li>
<li>thread映射到SM内的一个或多个SP上。多个线程可以同时在一个SM上运行，利用GPU的高度并行性。
通过这种映射关系，CUDA编程模型能够充分利用GPU的硬件特性，实现高性能并行计算。</li>
</ul>
<h2 id="shi-li-dai-ma">示例代码</h2>
<hr/>
<p>以下是一个完整的向量加法CUDA程序示例，包括主函数和内核函数。</p>
<div class="highlight"><pre><span></span><code><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;iostream&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;cuda_runtime.h&gt;</span>
<span class="c1">// 内核函数</span>
<span class="n">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">vector_add</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">N</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">idx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">idx</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">N</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">C</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">A</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">B</span><span class="p">[</span><span class="n">idx</span><span class="p">];</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>

<span class="kt">int</span><span class="w"> </span><span class="n">main</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1024</span><span class="p">;</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">threads_per_block</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">256</span><span class="p">;</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">num_blocks</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">N</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threads_per_block</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">threads_per_block</span><span class="p">;</span>

<span class="w">    </span><span class="kt">size_t</span><span class="w"> </span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// 分配内存</span>
<span class="w">    </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">A_host</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="n">size</span><span class="p">);</span>
<span class="w">    </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">B_host</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="n">size</span><span class="p">);</span>
<span class="w">    </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">C_host</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="n">size</span><span class="p">);</span>
<span class="w">    </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">A_device</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">B_device</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">C_device</span><span class="p">;</span>
<span class="w">    </span><span class="n">cudaMalloc</span><span class="p">((</span><span class="kt">void</span><span class="w"> </span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">A_device</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="p">);</span>
<span class="w">    </span><span class="n">cudaMalloc</span><span class="p">((</span><span class="kt">void</span><span class="w"> </span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">B_device</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="p">);</span>
<span class="w">    </span><span class="n">cudaMalloc</span><span class="p">((</span><span class="kt">void</span><span class="w"> </span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">C_device</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// 初始化数据</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">N</span><span class="p">;</span><span class="w"> </span><span class="o">++</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">A_host</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">i</span><span class="p">;</span>
<span class="w">        </span><span class="n">B_host</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">2</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="c1">// 复制数据到GPU</span>
<span class="w">    </span><span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">A_device</span><span class="p">,</span><span class="w"> </span><span class="n">A_host</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">cudaMemcpyHostToDevice</span><span class="p">);</span>
<span class="w">    </span><span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">B_device</span><span class="p">,</span><span class="w"> </span><span class="n">B_host</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">cudaMemcpyHostToDevice</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// 调用内核函数</span>
<span class="w">    </span><span class="n">vector_add</span><span class="o">&lt;&lt;&lt;</span><span class="n">num_blocks</span><span class="p">,</span><span class="w"> </span><span class="n">threads_per_block</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">A_device</span><span class="p">,</span><span class="w"> </span><span class="n">B_device</span><span class="p">,</span><span class="w"> </span><span class="n">C_device</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// 从GPU复制结果数据回主机</span>
<span class="w">    </span><span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">C_host</span><span class="p">,</span><span class="w"> </span><span class="n">C_device</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">cudaMemcpyDeviceToHost</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// 检查结果</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">N</span><span class="p">;</span><span class="w"> </span><span class="o">++</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">C_host</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">A_host</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">B_host</span><span class="p">[</span><span class="n">i</span><span class="p">])</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="n">std</span><span class="o">::</span><span class="n">cerr</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">"Error: Result mismatch at index "</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="w">            </span><span class="k">return</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">"Vector addition completed successfully!"</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>

<span class="w">    </span><span class="c1">// 释放内存</span>
<span class="w">    </span><span class="n">free</span><span class="p">(</span><span class="n">A_host</span><span class="p">);</span>
<span class="w">    </span><span class="n">free</span><span class="p">(</span><span class="n">B_host</span><span class="p">);</span>
<span class="w">    </span><span class="n">free</span><span class="p">(</span><span class="n">C_host</span><span class="p">);</span>
<span class="w">    </span><span class="n">cudaFree</span><span class="p">(</span><span class="n">A_device</span><span class="p">);</span>
<span class="w">    </span><span class="n">cudaFree</span><span class="p">(</span><span class="n">B_device</span><span class="p">);</span>
<span class="w">    </span><span class="n">cudaFree</span><span class="p">(</span><span class="n">C_device</span><span class="p">);</span>

<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div>
<h2 id="dai-ma-jie-du">代码解读</h2>
<hr/>
<p>在这个例子中，我们首先计算了所需的线程块数量，然后使用&lt;&lt;<num_blocks, threads_per_block="">&gt;&gt;配置启动vector_add内核函数。这个配置告诉CUDA运行时在GPU上创建num_blocks个线程块，每个线程块包含threads_per_block个线程。</num_blocks,></p>
<h3 id="cudanei-he-de-ding-yi-yu-diao-yong">cuda内核的定义与调用</h3>
<p>申明 <em>vector_add</em> ： </p>
<div class="highlight"><pre><span></span><code><span class="n">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">vector_add</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">A</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">B</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">C</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">N</span><span class="p">)</span>
</code></pre></div>
<p>kernel函数使用 <code>__global__</code> 限定符进行声明，表示它是在主机（CPU）上调用，然后在设备（GPU）上运行的。然后CPU会将 <em>vector_add</em> 函数在所有被调用的GPU线程上并行，从而获得GPU加速。<br/>
<strong>关于 <code>__global__</code> 关键字：</strong>
1. 它们只能从主机（CPU）代码中调用，不能从设备（GPU）代码中调用。
2. 在调用时，需要指定执行配置（即grid和block的大小），使用&lt;&lt;&lt;...&gt;&gt;&gt;语法表示。
3. 返回值类型必须为void，因为kernel函数的执行是异步的，无法直接返回结果。结果通常通过参数传递，或者将结果写入全局内存。  </p>
<p>调用kernel函数时，需要指定执行配置，即grid和block的大小。执行配置使用&lt;&lt;&lt;...&gt;&gt;&gt;语法表示，例如：</p>
<div class="highlight"><pre><span></span><code><span class="n">vector_add</span><span class="o">&lt;&lt;&lt;</span><span class="n">num_blocks</span><span class="p">,</span><span class="w"> </span><span class="n">threads_per_block</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">A_device</span><span class="p">,</span><span class="w"> </span><span class="n">B_device</span><span class="p">,</span><span class="w"> </span><span class="n">C_device</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="p">);</span>
</code></pre></div>
<p>其中，num_blocks定义了grid的大小（线程块的数量），而threads_per_block定义了block的大小（每个线程块中的线程数量）。括号内是传递给kernel函数的参数。该函数将在GPU上启动，实现了两个向量A和B相加的操作，并将结果存储在向量C中。它由多个线程并行执行，每个线程负责一个元素的相加操作。</p>
<h3 id="xian-cheng-idshi-ru-he-fen-pei-de">线程id是如何分配的</h3>
<p>那么GPU线程在GPU内部是如何调度的呢？要搞清楚这个问题，首先需要了解每个的线程的线程id是如何分配的。在 <em>vector_add</em> 函数内通过以下语句确定线程的id：</p>
<div class="highlight"><pre><span></span><code><span class="kt">int</span><span class="w"> </span><span class="n">idx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
</code></pre></div>
<p>在这个公式中，<code>blockIdx.x</code>表示线程所在的线程块的索引，<code>blockDim.x</code>表示每个线程块的线程数，<code>threadIdx.x</code>表示线程在线程块中的索引。这个公式将线程块和线程的索引映射到一个一维数据空间中的全局索引。需要注意的是，<strong>blockIdx</strong>、<strong>threadIdx</strong>和<strong>blockDim</strong>都是CUDA内置变量，不需要事先声明，可以直接在内核函数中使用。<br/>
<strong>blockIdx</strong> 是一个CUDA内置变量，它的类型是 dim3。除了 x 属性之外，<strong>blockIdx</strong> 还有两个属性：y 和 z。这三个属性（x、y 和 z）一起表示在一个三维线程网格中线程所在的线程块的索引。在CUDA内核函数中，可以使用这些属性来计算线程在多维数据空间中的位置。<br/>
在一维线程网格中，只需要使用 <code>blockIdx.x</code>。对于二维线程网格，可以使用 <code>blockIdx.x</code> 和 <code>blockIdx.y</code>；对于三维线程网格，需要使用 <code>blockIdx.x</code>、<code>blockIdx.y</code> 和 <code>blockIdx.z</code>。类似地，<strong>threadIdx</strong> 和 <strong>blockDim</strong> 也有 x、y 和 z 这三个属性。</p>
<p>如果将grid扩展到二维，以下是一个二维线程网格的示例，用于计算线程在二维数据空间中的位置：</p>
<div class="highlight"><pre><span></span><code><span class="kt">int</span><span class="w"> </span><span class="n">idx_x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
<span class="kt">int</span><span class="w"> </span><span class="n">idx_y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">blockIdx</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">blockDim</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">;</span>
</code></pre></div>
    <!-- <div class="aspect-w-16 aspect-h-9 mx-auto"></div> CSS placeholder -->
  </div>
  <footer class="flex flex-col mt-10 ">
    <ul class="flex flex-wrap">
        <li
          class="bg-zinc-200 hover:bg-zinc-300 dark:hover:bg-zinc-800 dark:bg-zinc-700 text-zinc-600 dark:text-zinc-300 mb-2 mr-2 px-3 py-1.5 rounded-md transition ease-in active:-translate-y-1 active:scale-110 duration-75">
          <a href="/tag/bing-xing-ji-suan.html">并行计算</a>
        </li>
        <li
          class="bg-zinc-200 hover:bg-zinc-300 dark:hover:bg-zinc-800 dark:bg-zinc-700 text-zinc-600 dark:text-zinc-300 mb-2 mr-2 px-3 py-1.5 rounded-md transition ease-in active:-translate-y-1 active:scale-110 duration-75">
          <a href="/tag/cpp.html">cpp</a>
        </li>
        <li
          class="bg-zinc-200 hover:bg-zinc-300 dark:hover:bg-zinc-800 dark:bg-zinc-700 text-zinc-600 dark:text-zinc-300 mb-2 mr-2 px-3 py-1.5 rounded-md transition ease-in active:-translate-y-1 active:scale-110 duration-75">
          <a href="/tag/cuda.html">cuda</a>
        </li>
    </ul>
    <div class="flex w-full my-2 bg-zinc-200 dark:bg-zinc-700 rounded-lg">
      <div class="w-1/2 rounded-l-lg"></div>
    </div>
    <div class="flex bg-zinc-200 dark:bg-zinc-700 py-2 rounded-lg justify-center space-x-2 text-xs">
      <ul>
        <li class="bg-gray-900 p-1 text-white rounded-md">
          <a target="_blank" rel="noopener noreferrer" title="twitter" aria-label="share Features on twitter"
            href="https://twitter.com/intent/tweet/?text=Features&amp;url=/cudaji-chu-zhi-shi-yi.html">
            <i class="fab fa-twitter fa-2x" aria-hidden="true"></i>
          </a>
        </li>
      </ul>
      <ul>
        <li class="bg-gray-900 p-1 text-white rounded-md">
          <a target="_blank" rel="noopener noreferrer" title="linkedin" aria-label="share Features on linkedin"
            href="https://www.linkedin.com/sharing/share-offsite/?url=/cudaji-chu-zhi-shi-yi.html">
            <i class="fab fa-linkedin fa-2x" aria-hidden="true"></i>
          </a>
        </li>
      </ul>
      <ul>
        <li class="bg-gray-900 p-1 text-white rounded-md">
          <a target="_blank" rel="noopener noreferrer" title="reddit" aria-label="share Features on reddit"
            href="https://reddit.com/submit?url=/cudaji-chu-zhi-shi-yi.html">
            <i class="fab fa-reddit fa-2x" aria-hidden="true"></i>
          </a>
        </li>
      </ul>
      <ul>
        <li class="bg-gray-900 p-1 text-white rounded-md">
          <a target="_blank" rel="noopener noreferrer" title="facebook" aria-label="share Features on facebook"
            href="https://facebook.com/sharer/sharer.php?u=/cudaji-chu-zhi-shi-yi.html">
            <i class="fab fa-facebook fa-2x" aria-hidden="true"></i>
          </a>
        </li>
      </ul>
      <ul>
        <li class="bg-gray-900 p-1 text-white rounded-md">
          <a target="_blank" rel="noopener noreferrer" title="whatsapp" aria-label="share Features on whatsapp"
            href="https://api.whatsapp.com/send?text=Features - /cudaji-chu-zhi-shi-yi.html">
            <i class="fab fa-whatsapp fa-2x" aria-hidden="true"></i>
          </a>
        </li>
      </ul>
      <ul>
        <li class="bg-gray-900 p-1 text-white rounded-md">
          <a target="_blank" rel="noopener noreferrer" title="telegram" aria-label="share Features on telegram"
            href="https://telegram.me/share/url?text=Features&amp;url=/cudaji-chu-zhi-shi-yi.html">
            <i class="fab fa-telegram fa-2x" aria-hidden="true"></i>
          </a>
        </li>
      </ul>
    </div>
  </footer>
  <div>
  </div>
</main>

    </div>
    <footer class="flex w-full text-xs justify-center mt-10 mb-6 text-zinc-600 dark:text-zinc-400">
        <div class="px-4">
            <span>©2023&nbsp;&#8226;&nbsp;</span>Powered by
            <a class="underline" href="https://getpelican.com/">Pelican</a>&nbsp;&
            <a class="underline" href="https://github.com/aleylara/Papyrus">Papyrus</a>
        </div>
    </footer>


    <script>
        let themeToggleDarkIcon = document.getElementById('theme-toggle-dark-icon');
        let themeToggleLightIcon = document.getElementById('theme-toggle-light-icon');
        if (localStorage.getItem('color-theme') === 'dark' || (!('color-theme' in localStorage) && window.matchMedia(
                '(prefers-color-scheme: dark)').matches)) {
            themeToggleLightIcon.classList.remove('hidden');
        } else {
            themeToggleDarkIcon.classList.remove('hidden');
        }
        let themeToggleBtn = document.getElementById('theme-toggle');
        themeToggleBtn.addEventListener('click', function () {
            themeToggleDarkIcon.classList.toggle('hidden');
            themeToggleLightIcon.classList.toggle('hidden');
            if (localStorage.getItem('color-theme')) {
                if (localStorage.getItem('color-theme') === 'light') {
                    document.documentElement.classList.add('dark');
                    localStorage.setItem('color-theme', 'dark');
                } else {
                    document.documentElement.classList.remove('dark');
                    localStorage.setItem('color-theme', 'light');
                }
            } else {
                if (document.documentElement.classList.contains('dark')) {
                    document.documentElement.classList.remove('dark');
                    localStorage.setItem('color-theme', 'light');
                } else {
                    document.documentElement.classList.add('dark');
                    localStorage.setItem('color-theme', 'dark');
                }
            }
        });
    </script>
</body>

</html>